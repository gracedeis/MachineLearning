{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKTNq-JPXsBq"
   },
   "source": [
    "# Coursework: A Classification Problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLHElFLknkYS"
   },
   "source": [
    "# 1. Dataset, libraries upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uePlyoC8mMtP",
    "outputId": "4102b5eb-8e73-4832-a67d-9c1af1782f91"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwOn_j3VmUMc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fhgb605tm5vV",
    "outputId": "dd304b10-b219-48db-ae47-57bf498e270d"
   },
   "outputs": [],
   "source": [
    "data = open('/content/drive/MyDrive/Colab Notebooks/ML2/Data/data.txt').readlines()\n",
    "data = [i.split() for i in data]\n",
    "\n",
    "column_names = [\n",
    "    \"pelvic_incidence\",\n",
    "    \"pelvic_tilt\",\n",
    "    \"lumbar_lordosis_angle\",\n",
    "    \"sacral_slope\",\n",
    "    \"pelvic_radius\",\n",
    "    \"grade_of_spondylolisthesis\",\n",
    "    \"class\"\n",
    "]\n",
    "\n",
    "data = pd.DataFrame(columns = column_names, data = data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "uB6ygg-QnD8W",
    "outputId": "7c67db17-6bec-475e-c6de-4d9770b806a3"
   },
   "outputs": [],
   "source": [
    "print(data.info())\n",
    "print(data.describe())\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p8UVY9cngcZ"
   },
   "source": [
    "* No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OylVkhBaoIKJ"
   },
   "source": [
    "# 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPGGnGlZoD5H",
    "outputId": "2538875a-bd8b-49e4-848c-c7bfbac53740"
   },
   "outputs": [],
   "source": [
    "data[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tJ5esfIMndUV",
    "outputId": "b1ba35de-460a-41ae-a464-5713ddfd3050"
   },
   "outputs": [],
   "source": [
    "data.loc[data['class'] == 'NO',['class']] = 0\n",
    "data.loc[data['class'] == 'AB',['class']] = 1\n",
    "for i in column_names:\n",
    "  data[i] = pd.to_numeric(data[i])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj_aHGw7sQuy"
   },
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udZYF5MsZuIQ"
   },
   "source": [
    "## 3.1. Distribution of vairables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "gzuxqh3DZsWZ",
    "outputId": "888b3c68-d1ed-4146-abc3-ead16226b3c1"
   },
   "outputs": [],
   "source": [
    "# Column name mapping for display\n",
    "column_name_mapping = {\n",
    "    \"pelvic_incidence\": \"Pelvic Incidence\",\n",
    "    \"pelvic_tilt\": \"Pelvic Tilt\",\n",
    "    \"lumbar_lordosis_angle\": \"Lumbar Lordosis Angle\",\n",
    "    \"sacral_slope\": \"Sacral Slope\",\n",
    "    \"pelvic_radius\": \"Pelvic Radius\",\n",
    "    \"grade_of_spondylolisthesis\": \"Grade of Spondylolisthesis\"\n",
    "}\n",
    "\n",
    "features = [col for col in data.columns if col != 'class']\n",
    "colors = sns.color_palette(\"husl\", len(features))\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "for i, column in enumerate(features):\n",
    "    data[column].plot.hist(\n",
    "        ax=axes[i],\n",
    "        bins=20,\n",
    "        edgecolor='black',\n",
    "        color=colors[i],\n",
    "        alpha=0.8\n",
    "    )\n",
    "    fixedname = column_name_mapping[column]\n",
    "    axes[i].set_title(f\"Histogram of {fixedname}\")\n",
    "    axes[i].set_xlabel(fixedname)\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "plt.suptitle(\"Histograms of Numerical Features\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_GOQr8ViJjCZ",
    "outputId": "103bb0d8-732e-41a6-a722-71e54234a963"
   },
   "outputs": [],
   "source": [
    "column_names = ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle',\n",
    "       'sacral_slope', 'pelvic_radius', 'grade_of_spondylolisthesis', 'class']\n",
    "\n",
    "numeric_features = column_names[:-1]\n",
    "X = data[numeric_features].values\n",
    "names = numeric_features\n",
    "sns.pairplot(data, vars=numeric_features, hue=\"class\", diag_kind=\"kde\", palette=\"Set1\", markers=[\"o\", \"s\"])\n",
    "plt.savefig(\"pre_stand.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hMsSidZkKDRb",
    "outputId": "309fd5f5-e0a5-4b04-c101-615a2a04316a"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data2 = data.copy()\n",
    "data2[numeric_features] = scaler.fit_transform(data2[numeric_features])\n",
    "\n",
    "numeric_features = column_names[:-1]\n",
    "X = data2[numeric_features].values\n",
    "names = numeric_features\n",
    "sns.pairplot(data2, vars=numeric_features, hue=\"class\", diag_kind=\"kde\", palette=\"Set1\", markers=[\"o\", \"s\"])\n",
    "plt.suptitle(\"Pairplot of Vertebral Column Data by Class\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "-TB6PGcVr1fC",
    "outputId": "2cd034f4-59a5-40ca-f91c-65748cf94b87"
   },
   "outputs": [],
   "source": [
    "boxplot_colors = ['#FF9999', '#99FF99', '#9999FF', '#FFCC99', '#CC99FF', '#66CCCC']\n",
    "\n",
    "features = [col for col in data.columns if col != 'class']\n",
    "plt.figure(figsize=(12, 6))\n",
    "box = plt.boxplot(\n",
    "    data[features].values,\n",
    "    patch_artist=True,\n",
    "    labels=[column_name_mapping[col] for col in features]\n",
    ")\n",
    "\n",
    "for patch, color in zip(box['boxes'], boxplot_colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.xticks(rotation=30, ha='right')  # Tilted x-axis labels for readability\n",
    "plt.title(\"Boxplot of Numerical Features (Detecting Outliers)\", fontsize=14)\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "UoHi5-qPcw-h",
    "outputId": "6deab866-a694-44dc-b4fb-7c404f5c6795"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 4.5))\n",
    "ax = sns.countplot(x=\"class\", data=data, palette=\"coolwarm\")\n",
    "plt.title(\"Class Distribution(NO vs. AB)\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width()/2.,\n",
    "        height + 0.3,\n",
    "        f'{int(height)}',\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "plt.xticks([0, 1], ['Normal', 'Abnormal'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbsmhKMBamfd"
   },
   "source": [
    "## 3.2. Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "LLqayHJCZsRm",
    "outputId": "d7ea381c-7024-4bb1-887b-b1cfd5fd75d8"
   },
   "outputs": [],
   "source": [
    "# Feature variables\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data.drop(columns=[\"class\"]).corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "id": "qhhTppwKZsO2",
    "outputId": "bc57114f-0391-41b6-abbe-06495d7a43f4"
   },
   "outputs": [],
   "source": [
    "# Including target variables\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WPeWh6WexW_"
   },
   "source": [
    "## 3.3. PCA Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "U8AAEopxZsKo",
    "outputId": "edc195ba-1353-42a7-c8b7-5c75fbf98dd2"
   },
   "outputs": [],
   "source": [
    "X = data[numeric_features]\n",
    "y = data['class']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(X_scaled)\n",
    "pca_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "pca_df['class'] = y\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='PC1', y='PC2', data=pca_df)\n",
    "plt.title(\"PCA of Vertebral Column Data\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIL3jPw56HzD"
   },
   "source": [
    "Standardscaler\n",
    "* Mean ‚âà 0\n",
    "Standard Deviation ‚âà 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XeCI_Olr7YH"
   },
   "source": [
    "# 4. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnOTnzIPsbMR"
   },
   "outputs": [],
   "source": [
    "# Scaling\n",
    "values = data.drop(columns=[\"class\"]).values\n",
    "values = StandardScaler().fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS9-F_RusbJg",
    "outputId": "d27b4423-258f-443e-8d54-b2e6c71e4a6b"
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCAthreshold = 0.9\n",
    "Pca = PCA(n_components = PCAthreshold, svd_solver=\"full\")\n",
    "reducedData = Pca.fit_transform(values)\n",
    "reducedData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV_AbEYhvHG5"
   },
   "source": [
    "Setting: 90% variance -> 4 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "id": "bpY5WYTWtvIc",
    "outputId": "7c19528e-84f8-47c8-c773-66e5a5cc0a4e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_full = PCA(svd_solver=\"full\")\n",
    "pca_full.fit(values)\n",
    "\n",
    "explained_variance_ratio = pca_full.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "n_components = range(1, len(explained_variance_ratio) + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scree Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(n_components, explained_variance_ratio, 'o-', linewidth=2, markersize=8)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "\n",
    "# Accumulate\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(n_components, cumulative_variance_ratio, 'o-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Threshold')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# elbow point\n",
    "components_needed_for_90 = np.argmax(cumulative_variance_ratio >= 0.9) + 1\n",
    "print(f\"Components needed for 90% variance: {components_needed_for_90}\")\n",
    "print(\"Explained variance by component:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio[:10], 1):\n",
    "    print(f\"PC{i}: {ratio:.4f} ({cumulative_variance_ratio[i-1]:.4f} cumulative)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1cVbV1wr9zc"
   },
   "source": [
    "# 5. Factoral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1rB1ztCwdu8",
    "outputId": "66cf9d86-028f-4e5b-bb93-d8796bb3156b"
   },
   "outputs": [],
   "source": [
    "!pip install factor_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4JF3m92au9z_",
    "outputId": "a8241e54-3a7a-481c-f41b-8144fb6441f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "max_factors = min(6, X_scaled.shape[1])\n",
    "\n",
    "variance_explained = []\n",
    "cumulative_variance = []\n",
    "\n",
    "for n_factors in range(1, max_factors + 1):\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax')\n",
    "    fa.fit(X_scaled)\n",
    "\n",
    "    variance = fa.get_factor_variance()[1]\n",
    "    variance_explained.append(sum(variance))\n",
    "\n",
    "    cumulative_variance.append(sum(variance))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Scree Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, max_factors + 1), variance_explained, 'o-', linewidth=2, markersize=8)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of Factors')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.grid(True)\n",
    "\n",
    "# Accumulated\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, max_factors + 1), cumulative_variance, 'o-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=0.7, color='r', linestyle='--', label='90% Explained Variance')\n",
    "plt.title('Cumulative Variance Explained')\n",
    "plt.xlabel('Number of Factors')\n",
    "plt.ylabel('Cumulative Variance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Variance explained by number of factors:\")\n",
    "for i, var in enumerate(variance_explained, 1):\n",
    "    print(f\"{i} factor(s): {var:.4f} ({cumulative_variance[i-1]:.4f} cumulative)\")\n",
    "\n",
    "# elbow method\n",
    "variance_diff = np.diff(variance_explained)\n",
    "variance_diff_rate = np.diff(variance_diff)\n",
    "suggested_factors = np.argmin(variance_diff_rate) + 3\n",
    "\n",
    "print(f\"\\nSuggested number of factors based on elbow method: {suggested_factors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdVqC5BHsW-J"
   },
   "source": [
    "# 6. Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "PhSziXXv5wgA",
    "outputId": "0d8c0e31-3c43-4db3-941a-857c3b48d467"
   },
   "outputs": [],
   "source": [
    "X_scaled=pd.DataFrame(X_scaled, columns=data.columns[:-1])\n",
    "data_scaled=pd.concat([X_scaled, data['class']], axis=1)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygvqdwPusv6S"
   },
   "source": [
    "### 6.1. K-nearst classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMcvjU70zbbf"
   },
   "source": [
    "#### 6.1.1. Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOakKggqoeTi",
    "outputId": "b05403c1-8db2-42e3-efd6-a8e8ca9d46ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE (resampling)\n",
    "train, test = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "X_train, X_test = train.drop('class', axis=1), test.drop('class', axis=1)\n",
    "y_train, y_test = train['class'], test['class']\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_values = range(5, 30, 2)\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')   # imbalanced\n",
    "    scores = cross_val_score(knn, X_train_balanced, y_train_balanced, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# optimal k\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "best_score = np.max(cv_scores)\n",
    "\n",
    "print(\"Optimal k:\", optimal_k)\n",
    "print(f\"Best cross-validation score: {best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbtNkp0J7c_O"
   },
   "source": [
    "The way to set the value of k (the number of nearest neighbors) in KNN generally depends on the size and distribution of the data.\n",
    "\n",
    "‚úÖ Common Guidelines for Setting k:\n",
    "\n",
    "Set k to an odd number: For binary classification (0/1), it is recommended to set k as an odd number to avoid ties.\n",
    "\n",
    "‚àö(number of data points): Empirically, it is suggested that k ‚âà ‚àö(total number of samples).\n",
    "\n",
    "For the current data with 310 samples:\n",
    "\n",
    "ùëò\n",
    "‚âà\n",
    "310\n",
    "‚âà\n",
    "17.6\n",
    "k‚âà\n",
    "310\n",
    "‚Äã\n",
    " ‚âà17.6\n",
    "Small k value (Risk of Underfitting): If k is too small, the model becomes sensitive to noise (overfitting). (e.g., when k=1, the model only looks at the closest single data point).\n",
    "\n",
    "Large k value (Risk of Underfitting): If k is too large, the model may overly simplify the patterns (underfitting), which will reduce its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6OlPU6LvAM7"
   },
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "\n",
    "* weights='distance' <br>\n",
    "When weights='distance' is set, closer data points receive higher weights.\n",
    "In other words, if minority class data points are close, they are not ignored by the majority class.\n",
    "The default value weights='uniform' gives equal weight to all neighbors, which is disadvantageous for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ecxdpwrT0r-y",
    "outputId": "19e807ba-db1c-4a16-815b-9c2863bf9845"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, cv_scores, marker='o', color='b', label=\"Cross-Validation Accuracy\")\n",
    "plt.axvline(optimal_k, color='r', linestyle='--', label=f\"Optimal k={optimal_k}\")\n",
    "plt.xlabel(\"Number of Neighbors (k)\")\n",
    "plt.ylabel(\"Cross-Validation Accuracy\")\n",
    "plt.title(\"KNN: Choosing the Optimal k\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATUr7s0wsvhK",
    "outputId": "760db5ae-f048-4fc4-a374-13c4fc64377b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "knn = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "knn.fit(X_train_balanced, y_train_balanced)\n",
    "y_predict = knn.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "iO-_u34LtEZS",
    "outputId": "aa7f0e9f-783f-42a0-d0d9-8a8672f094f5"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Apply PCA to reduce to 2 components\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_balanced)  # Apply PCA to the training data\n",
    "\n",
    "knn_vis = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "knn_vis.fit(X_pca, y_train_balanced)\n",
    "\n",
    "x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "Z = knn_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot( x=X_pca[:, 0],y=X_pca[:, 1], hue=pd.Series(y_train_balanced).map({0: \"Normal\", 1: \"Abnormal\"}), palette=cmap_bold, edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"KNN Decision Boundary (PCA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nWpgCmSgjiVC",
    "outputId": "a1753a11-4fae-4362-c7ec-60f6502516b8"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "feature_pairs = [\n",
    "    (\"pelvic_incidence\", \"sacral_slope\"),\n",
    "    (\"grade_of_spondylolisthesis\", \"pelvic_radius\"),\n",
    "    (\"pelvic_incidence\", \"grade_of_spondylolisthesis\"),\n",
    "    (\"pelvic_incidence\", \"pelvic_tilt\")]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "for ax, (feature_x, feature_y) in zip(axes.flatten(), feature_pairs):\n",
    "    X_vis = X_train_balanced[[feature_x, feature_y]].values\n",
    "    y_vis = y_train_balanced.values\n",
    "\n",
    "    knn_vis = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "    knn_vis.fit(X_vis, y_vis)\n",
    "\n",
    "    x_min, x_max = X_vis[:, 0].min() - 1, X_vis[:, 0].max() + 1\n",
    "    y_min, y_max = X_vis[:, 1].min() - 1, X_vis[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "    Z = knn_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "    cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "    sns.scatterplot(x=X_vis[:, 0], y=X_vis[:, 1], hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}), palette=cmap_bold, edgecolor=\"k\", ax=ax)\n",
    "\n",
    "    ax.set_xlabel(feature_x)\n",
    "    ax.set_ylabel(feature_y)\n",
    "    ax.set_title(f\"KNN Decision Boundary: {feature_x} vs {feature_y}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHV37s0F0CW4"
   },
   "source": [
    "#### 6.1.2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_hhDeCa0Ec5",
    "outputId": "f3970f40-7143-421a-ab4e-8c56e63c4d81"
   },
   "outputs": [],
   "source": [
    "# train, test = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "# X_train, X_test = train.drop('class', axis=1), test.drop('class', axis=1)\n",
    "# y_train, y_test = train['class'], test['class']\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "PCAthreshold = 0.9    # (or n_components = 4)\n",
    "pca = PCA(n_components=PCAthreshold, svd_solver=\"full\")\n",
    "pca.fit(X_train_balanced)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_balanced)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(f\"Original features: {X_train_balanced.shape[1]}\")\n",
    "print(f\"After PCA reduction features: {X_train_pca.shape[1]}\")\n",
    "\n",
    "k_values = range(5, 30, 2)\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    scores = cross_val_score(knn, X_train_pca, y_train_balanced, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "best_score = np.max(cv_scores)\n",
    "\n",
    "print(\"Optimal k:\", optimal_k)\n",
    "print(f\"Best cross-validation score: {best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jf3sFeXU0Ear",
    "outputId": "7a6dac8e-c0eb-423b-d1ea-bd7bfe213f9f"
   },
   "outputs": [],
   "source": [
    "final_knn = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "final_knn.fit(X_train_pca, y_train_balanced)\n",
    "y_predict = final_knn.predict(X_test_pca)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "FkLoXv5Gth6P",
    "outputId": "565b8d01-679b-416c-9736-08956968b78f"
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "X_train_vis = X_train_pca[:, :2] # first 2 component\n",
    "X_test_vis = X_test_pca[:, :2] # first 2 component\n",
    "y_vis = y_train_balanced.values\n",
    "\n",
    "final_knn_vis = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "final_knn_vis.fit(X_train_vis, y_vis)\n",
    "\n",
    "x_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\n",
    "y_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "Z = final_knn_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_vis[:, 0],\n",
    "    y=X_train_vis[:, 1],\n",
    "    hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}),\n",
    "    palette=cmap_bold,\n",
    "    edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"KNN Decision Boundary (PCA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfWGIOHu40IE"
   },
   "source": [
    "### 6.1.3. FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOeAYcbv0EYN",
    "outputId": "42f08a95-0477-4660-e724-2b06288b950f"
   },
   "outputs": [],
   "source": [
    "# Train FA\n",
    "num_factors = 3\n",
    "fa = FactorAnalysis(n_components=num_factors, random_state=42)\n",
    "fa.fit(X_train_balanced)\n",
    "\n",
    "X_train_fa = fa.transform(X_train_balanced)\n",
    "X_test_fa = fa.transform(X_test)\n",
    "\n",
    "print(f\"After FA features: {X_train_fa.shape[1]}\")\n",
    "\n",
    "k_values = range(5, 30, 2)\n",
    "cv_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    scores = cross_val_score(knn, X_train_fa, y_train_balanced, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "optimal_k = k_values[np.argmax(cv_scores)]\n",
    "best_score = np.max(cv_scores)\n",
    "\n",
    "print(\"Optimal k:\", optimal_k)\n",
    "print(f\"Best cross-validation score: {best_score:.3f}\")\n",
    "\n",
    "final_knn = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "final_knn.fit(X_train_fa, y_train_balanced)\n",
    "y_predict = final_knn.predict(X_test_fa)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "C_bs5lf40ajQ",
    "outputId": "1a07f456-ece9-4dc3-a54c-e4d007b74f6b"
   },
   "outputs": [],
   "source": [
    "X_train_vis = X_train_fa[:, :2] # first 2 component\n",
    "X_test_vis = X_test_fa[:, :2] # first 2 component\n",
    "y_vis = y_train_balanced.values\n",
    "\n",
    "final_knn_vis = KNeighborsClassifier(n_neighbors=optimal_k, weights='distance')\n",
    "final_knn_vis.fit(X_train_vis, y_vis)\n",
    "\n",
    "x_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\n",
    "y_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "Z = final_knn_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_vis[:, 0],\n",
    "    y=X_train_vis[:, 1],\n",
    "    hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}),\n",
    "    palette=cmap_bold,\n",
    "    edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"FA Component 1\")\n",
    "plt.ylabel(\"FA Component 2\")\n",
    "plt.title(\"KNN Decision Boundary (FA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY_jov5aszVd"
   },
   "source": [
    "### 6.2. RandomForest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duLDlc-TAwAB"
   },
   "source": [
    "#### 6.2.1. Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcB_5KFcsvfD",
    "outputId": "fce2bf80-fa81-4e6f-cd49-6e523741f191"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [100, 150, 200], 'max_depth': [10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4],}\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')  # same condition(cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Best Cross-Validation Score: {best_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8y7BoBl67i_"
   },
   "source": [
    "* class_weight='balanced': imbalanced coordination\n",
    "* cv = 5: same condition as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bz9BYPIIsvc8",
    "outputId": "c67f99e8-0795-4036-ae3b-c2a0719082e8"
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42, **best_params)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predict = rfc.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "TEbZ48zO71OC",
    "outputId": "f58e9f3a-0aec-45c5-93d3-de7d0c95e964"
   },
   "outputs": [],
   "source": [
    "# Checking the feature importance\n",
    "feature_importance = rfc.feature_importances_\n",
    "\n",
    "features = X_train.columns\n",
    "sorted_idx = feature_importance.argsort()[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=feature_importance[sorted_idx], y=features[sorted_idx], palette=\"magma\")\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqgrcugJ6ijF"
   },
   "source": [
    "#### 6.2.2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "maSIB9wj6fAt",
    "outputId": "9d018267-1359-47af-c165-5f3578b43f99"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Best Cross-Validation Score: {best_score:.3f}\")\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42, **best_params)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "y_predict = rfc.predict(X_test_pca)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmctIc-86l6A"
   },
   "source": [
    "#### 6.2.3. FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aPRMiBs6fiD",
    "outputId": "d3eba618-edf1-4306-8704-d88f889393fa"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train_fa, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Best Cross-Validation Score: {best_score:.3f}\")\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', random_state=42, **best_params)\n",
    "rfc.fit(X_train_fa, y_train)\n",
    "y_predict = rfc.predict(X_test_fa)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB5qHbX_6sFj"
   },
   "source": [
    "### 6.3. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVmtSEkh6pfb"
   },
   "source": [
    "#### 6.3.1. Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trx2lQOA6uS_"
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_scaled, test_size=0.2, random_state=42)    # Scaled data\n",
    "X_train, X_test = train.drop('class', axis=1), test.drop('class', axis=1)\n",
    "y_train, y_test = train['class'], test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnKj6gLdCl0z",
    "outputId": "a1fde9b9-b39f-47b5-90eb-58ac1d2f5266"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE     # imbalanced coordination\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# hyperparameter tunning\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto', 0.1, 1], 'kernel': ['rbf', 'linear']}\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0E4cDV0EQYi",
    "outputId": "7899dbd6-e95e-479d-a80a-dde9ad5dd396"
   },
   "outputs": [],
   "source": [
    "svm = SVC(class_weight='balanced', random_state=42, **best_params)\n",
    "svm.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_predict = svm.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fwPf-V26vOz"
   },
   "source": [
    "#### 6.3.2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKhm3yMq61Hr",
    "outputId": "ca60a630-4b3b-4b3f-9179-bec965fc05bc"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_pca, y_train_resampled = smote.fit_resample(X_train_pca, y_train)\n",
    "\n",
    "# hyperparameter tunning\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto', 0.1, 1], 'kernel': ['rbf', 'linear']}\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled_pca, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=42, **best_params)\n",
    "svm.fit(X_train_resampled_pca, y_train_resampled)\n",
    "\n",
    "y_predict = svm.predict(X_test_pca)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAWJ9GtD6u_T"
   },
   "source": [
    "#### 6.3.3. FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCggvQSS61FU",
    "outputId": "40fe1f97-fb02-42d8-eeef-c4f08deffd07"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled_fa, y_train_resampled = smote.fit_resample(X_train_fa, y_train)\n",
    "\n",
    "# hyperparameter tunning\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto', 0.1, 1], 'kernel': ['rbf', 'linear']}\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled_fa, y_train_resampled)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "svm = SVC(class_weight='balanced', random_state=42, **best_params)\n",
    "svm.fit(X_train_resampled_fa, y_train_resampled)\n",
    "\n",
    "y_predict = svm.predict(X_test_fa)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vQPvyuBvpU"
   },
   "source": [
    "### 6.4. Discriminant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjLEFZRWBzE9"
   },
   "source": [
    "#### 6.4.1. Original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_z7Qzhgsshp3",
    "outputId": "bbf0bd88-5c59-4d60-9aee-3453e929cd1a"
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "print(f\"Resampled class distribution: {Counter(y_train_balanced)}\")\n",
    "\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = class_counts / np.sum(class_counts)\n",
    "\n",
    "param_grid = [{'solver': ['svd'], 'priors': [class_weights]},\n",
    "    {'solver': ['lsqr'], 'shrinkage': [None, 'auto', 0.1, 0.2], 'priors': [class_weights]},\n",
    "    {'solver': ['eigen'], 'shrinkage': [None, 'auto'], 'priors': [class_weights]}]\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=-1,\n",
    "                           scoring='f1_weighted', error_score='raise')\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "lda_best = LinearDiscriminantAnalysis(**best_params)\n",
    "lda_best.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_predict = lda_best.predict(X_test)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "pWqmJpkP1Ju7",
    "outputId": "11cd1296-a768-4a1f-93fc-051df60e5a42"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca_balanced = pca.fit_transform(X_train_balanced)\n",
    "\n",
    "X_vis = X_pca_balanced\n",
    "y_vis = y_train_balanced\n",
    "\n",
    "feature_x = 0\n",
    "feature_y = 1\n",
    "\n",
    "x_min, x_max = X_vis[:, feature_x].min() - 1, X_vis[:, feature_x].max() + 1\n",
    "y_min, y_max = X_vis[:, feature_y].min() - 1, X_vis[:, feature_y].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "grid_df = pd.DataFrame(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]), columns=X_train.columns)\n",
    "\n",
    "Z = lda_best.predict(grid_df)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot(x=X_pca_balanced[:, feature_x], y=X_pca_balanced[:, feature_y],\n",
    "                hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}),\n",
    "                palette=cmap_bold, edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"LDA Decision Boundary (PCA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rezkgQ3l6F4y"
   },
   "source": [
    "* LDA (Linear Discriminant Analysis) is a linear classification model, so its decision boundary always appears as a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2-4iqiqB2Vf"
   },
   "source": [
    "#### 6.4.2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6QeCqKYC64dH",
    "outputId": "4f936b85-4b57-4a74-cd8e-cd9992091c7e"
   },
   "outputs": [],
   "source": [
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_pca, y_train)\n",
    "\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "print(f\"Resampled class distribution: {Counter(y_train_balanced)}\")\n",
    "\n",
    "# Define Parameter Grid with Priors Adjusted for Class Weights\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = class_counts / np.sum(class_counts)   # Normalize to sum=1\n",
    "\n",
    "param_grid = [\n",
    "    {'solver': ['svd'], 'priors': [class_weights]},\n",
    "    {'solver': ['lsqr'], 'shrinkage': [None, 'auto', 0.1, 0.2], 'priors': [class_weights]},\n",
    "    {'solver': ['eigen'], 'shrinkage': [None, 'auto'], 'priors': [class_weights]}\n",
    "]\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1_weighted', error_score='raise')\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "lda_best = LinearDiscriminantAnalysis(**best_params)\n",
    "lda_best.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_predict = lda_best.predict(X_test_pca)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "RwtTSjt26IlJ",
    "outputId": "a4813be4-0a3e-4e67-f916-a8404dbfefda"
   },
   "outputs": [],
   "source": [
    "X_train_vis = X_train_balanced[:, :2]\n",
    "X_test_vis = X_test_pca[:, :2]\n",
    "y_vis = y_train_balanced.values\n",
    "\n",
    "# Train LDA with best parameters\n",
    "lda_vis = LinearDiscriminantAnalysis(**best_params)\n",
    "lda_vis.fit(X_train_vis, y_vis)\n",
    "\n",
    "# Create mesh grid\n",
    "x_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\n",
    "y_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict on mesh grid\n",
    "Z = lda_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_vis[:, 0],\n",
    "    y=X_train_vis[:, 1],\n",
    "    hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}),\n",
    "    palette=cmap_bold,\n",
    "    edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"LDA Decision Boundary (PCA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPvR27QvB5Gg"
   },
   "source": [
    "#### 6.4.3. FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYMpIc2h64a4",
    "outputId": "5cbbea45-294b-4d94-c994-8fba6828ef1c"
   },
   "outputs": [],
   "source": [
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_fa, y_train)\n",
    "\n",
    "print(f\"Original class distribution: {Counter(y_train)}\")\n",
    "print(f\"Resampled class distribution: {Counter(y_train_balanced)}\")\n",
    "\n",
    "# Define Parameter Grid with Priors Adjusted for Class Weights\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = class_counts / np.sum(class_counts)   # Normalize to sum=1\n",
    "\n",
    "param_grid = [\n",
    "    {'solver': ['svd'], 'priors': [class_weights]},\n",
    "    {'solver': ['lsqr'], 'shrinkage': [None, 'auto', 0.1, 0.2], 'priors': [class_weights]},\n",
    "    {'solver': ['eigen'], 'shrinkage': [None, 'auto'], 'priors': [class_weights]}\n",
    "]\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1_weighted', error_score='raise')\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "lda_best = LinearDiscriminantAnalysis(**best_params)\n",
    "lda_best.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_predict = lda_best.predict(X_test_fa)\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion)\n",
    "\n",
    "# Scoring\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "recall = recall_score(y_test, y_predict)\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "\n",
    "precision = precision_score(y_test, y_predict)\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "print(f\"F1-score: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "bgnQe8ED6Jiy",
    "outputId": "b3280e24-ed9b-4c85-e3ba-26b3ce102843"
   },
   "outputs": [],
   "source": [
    "# Use first two factor analysis components for visualization\n",
    "X_train_vis = X_train_balanced[:, :2]\n",
    "X_test_vis = X_test_fa[:, :2]\n",
    "y_vis = y_train_balanced.values\n",
    "\n",
    "# Train LDA with best parameters\n",
    "lda_vis = LinearDiscriminantAnalysis(**best_params)\n",
    "lda_vis.fit(X_train_vis, y_vis)\n",
    "\n",
    "# Create mesh grid\n",
    "x_min, x_max = X_train_vis[:, 0].min() - 1, X_train_vis[:, 0].max() + 1\n",
    "y_min, y_max = X_train_vis[:, 1].min() - 1, X_train_vis[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict on mesh grid\n",
    "Z = lda_vis.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cmap_light = ListedColormap([\"#FF9999\", \"#9999FF\"])\n",
    "cmap_bold = [\"red\", \"blue\"]\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_vis[:, 0],\n",
    "    y=X_train_vis[:, 1],\n",
    "    hue=pd.Series(y_vis).map({0: \"Normal\", 1: \"Abnormal\"}),\n",
    "    palette=cmap_bold,\n",
    "    edgecolor=\"k\")\n",
    "\n",
    "plt.xlabel(\"Factor Component 1\")\n",
    "plt.ylabel(\"Factor Component 2\")\n",
    "plt.title(\"LDA Decision Boundary (FA Components)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELLKbGzPgytk"
   },
   "source": [
    "## 6.5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894
    },
    "id": "Bv290wL5g13Q",
    "outputId": "533145e1-aca7-4171-bec8-7b8c7b31f540"
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Model': ['KNN', 'Random Forest', 'SVM', 'LDA'],\n",
    "    'Original Accuracy': [0.839, 0.790, 0.823, 0.855],\n",
    "    'Original Recall': [0.818, 0.909, 0.818, 0.909],\n",
    "    'Original Precision': [0.949, 0.816, 0.923, 0.889],\n",
    "    'Original F1-score': [0.878, 0.860, 0.867, 0.899],\n",
    "    'PCA Accuracy': [0.823, 0.790, 0.839, 0.839],\n",
    "    'PCA Recall': [0.818, 0.864, 0.818, 0.818],\n",
    "    'PCA Precision': [0.923, 0.844, 0.947, 0.947],\n",
    "    'PCA F1-score': [0.867, 0.854, 0.878, 0.878],\n",
    "    'FA Accuracy': [0.726, 0.677, 0.661, 0.758],\n",
    "    'FA Recall': [0.727, 0.795, 0.727, 0.909],\n",
    "    'FA Precision': [0.865, 0.761, 0.780, 0.784],\n",
    "    'FA F1-score': [0.790, 0.778, 0.753, 0.842]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Highlight the best values in each metric column\n",
    "def highlight_best(val, col):\n",
    "    # Return yellow for the highest value in each column\n",
    "    return 'background-color: yellow' if val == metrics_df[col].max() else ''\n",
    "\n",
    "# Apply the highlighting function to the columns of interest\n",
    "styled_df = metrics_df.style.applymap(lambda val: highlight_best(val, 'Original Accuracy'), subset=['Original Accuracy'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'PCA Accuracy'), subset=['PCA Accuracy'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'FA Accuracy'), subset=['FA Accuracy'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'Original Recall'), subset=['Original Recall'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'PCA Recall'), subset=['PCA Recall'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'FA Recall'), subset=['FA Recall'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'Original Precision'), subset=['Original Precision'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'PCA Precision'), subset=['PCA Precision'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'FA Precision'), subset=['FA Precision'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'Original F1-score'), subset=['Original F1-score'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'PCA F1-score'), subset=['PCA F1-score'])\n",
    "styled_df = styled_df.applymap(lambda val: highlight_best(val, 'FA F1-score'), subset=['FA F1-score'])\n",
    "\n",
    "# Save the styled DataFrame as an image using matplotlib\n",
    "fig, ax = plt.subplots(figsize=(12, 6))  # Adjust the figure size as necessary\n",
    "ax.axis('off')  # Hide the axes\n",
    "\n",
    "# Create a table and apply the style\n",
    "table = ax.table(cellText=metrics_df.values, colLabels=metrics_df.columns, loc='center', cellLoc='center')\n",
    "\n",
    "# Apply custom styles to the table\n",
    "for i, col in enumerate(metrics_df.columns):\n",
    "    for j, cell in enumerate(table.get_celld().values()):\n",
    "        if cell.get_text().get_text() == str(metrics_df[col].max()):\n",
    "            cell.set_facecolor('yellow')  # Highlight the best values in yellow\n",
    "\n",
    "# Adjust the layout\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.auto_set_column_width(col=list(range(len(metrics_df.columns))))\n",
    "\n",
    "# Save the figure as an image\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WS9BwXFhg10p",
    "outputId": "41419d85-7355-423a-98a5-0c097335aafc"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data)\n",
    "\n",
    "# Separate Line Plots for each method\n",
    "methods = ['Original', 'PCA', 'FA']\n",
    "metrics = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
    "\n",
    "for method in methods:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for metric in metrics:\n",
    "        plt.plot(results['Model'], results[f'{method} {metric}'], marker='o', label=metric)\n",
    "\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{method} Model Performance Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9kmxpBjUwb88",
    "outputId": "a212a644-29c2-4765-acb6-97932c83eef6"
   },
   "outputs": [],
   "source": [
    "# KNN and LDA\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "knn_lda_data = df[df['Model'].isin(['KNN', 'LDA'])]\n",
    "\n",
    "results = pd.DataFrame(knn_lda_data)\n",
    "\n",
    "# Separate Line Plots for each method\n",
    "methods = ['Original', 'PCA', 'FA']\n",
    "metrics = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
    "\n",
    "for method in methods:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    for metric in metrics:\n",
    "        plt.plot(results['Model'], results[f'{method} {metric}'], marker='o', label=metric)\n",
    "\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'{method} Model Performance Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TQRxynNWg1yC",
    "outputId": "110ca120-43f9-41f4-ae7d-063d2da5e127"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data)\n",
    "\n",
    "# Creating the subplots for each metric and clustering method\n",
    "methods = ['Original', 'PCA', 'FA']\n",
    "metrics = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
    "\n",
    "for method in methods:\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axes[i].bar(results['Model'], results[f'{method} {metric}'], color=['b', 'g', 'r', 'purple'][i])\n",
    "        axes[i].set_title(f'{metric} - {method}')\n",
    "        axes[i].set_ylabel('Score')\n",
    "        for j, value in enumerate(results[f'{method} {metric}']):\n",
    "            axes[i].text(j, value + 0.01, f'{value:.3f}', ha='center', va='bottom')\n",
    "        axes[i].set_ylim(0, max(results[f'{method} {metric}']) + 0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-_qHk_mbxNZc",
    "outputId": "bca564d8-3c4f-455b-f2a3-cdee5b2db3d3"
   },
   "outputs": [],
   "source": [
    "# KNN and LDA\n",
    "\n",
    "methods = ['Original', 'PCA', 'FA']\n",
    "metrics = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
    "\n",
    "results = pd.DataFrame(knn_lda_data)\n",
    "\n",
    "for method in methods:\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 5))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axes[i].bar(results['Model'], results[f'{method} {metric}'], color=['b', 'g', 'r', 'purple'][i])\n",
    "        axes[i].set_title(f'{metric} - {method}')\n",
    "        axes[i].set_ylabel('Score')\n",
    "        for j, value in enumerate(results[f'{method} {metric}']):\n",
    "            axes[i].text(j, value + 0.01, f'{value:.3f}', ha='center', va='bottom')\n",
    "        axes[i].set_ylim(0, max(results[f'{method} {metric}']) + 0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "3CmTPf8HyN7W",
    "outputId": "93ed9a25-3dd9-4725-eb4a-4cc2d408373d"
   },
   "outputs": [],
   "source": [
    "models = ['KNN', 'LDA']\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.3\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "\n",
    "    for j, model in enumerate(models):\n",
    "        scores = [df[(df['Model'] == model)][f'{method} {metric}'].values[0] for method in methods]\n",
    "        ax.bar(x + j * width, scores, width, label=model)\n",
    "\n",
    "    ax.set_xticks(x + width / 2)\n",
    "    ax.set_xticklabels(methods)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(f\"{metric} Comparison\")\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcw7HjVArSj6"
   },
   "source": [
    "# 7. Unsupervised Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nz_qDDtJ60cK"
   },
   "outputs": [],
   "source": [
    "data = open('/content/drive/MyDrive/Colab Notebooks/ML2/Data/data.txt').readlines()\n",
    "data = [i.split() for i in data]\n",
    "\n",
    "column_names = [\n",
    "    \"pelvic_incidence\",\n",
    "    \"pelvic_tilt\",\n",
    "    \"lumbar_lordosis_angle\",\n",
    "    \"sacral_slope\",\n",
    "    \"pelvic_radius\",\n",
    "    \"grade_of_spondylolisthesis\",\n",
    "    \"class\"\n",
    "]\n",
    "\n",
    "data = pd.DataFrame(columns = column_names, data = data)\n",
    "data.head()\n",
    "\n",
    "X = data[numeric_features]\n",
    "y = data['class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7XvEDNJr98O"
   },
   "source": [
    "## 7.1 GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "empm7H54rRdW",
    "outputId": "f0695f10-83f5-4aff-b9b3-a9807846d26c"
   },
   "outputs": [],
   "source": [
    "gmm2 = GaussianMixture(n_components=2, random_state=2025)\n",
    "clusters_gmm2 = gmm2.fit_predict(X_scaled)\n",
    "\n",
    "data['GMM_cluster2'] = clusters_gmm2\n",
    "\n",
    "print(\"Cluster distribution:\", np.bincount(clusters_gmm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "0cIh1bW_rRa3",
    "outputId": "66fddf74-8953-4015-bb5f-920fc98f09a1"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "custom_palette = [\"#377eb8\",\"#e41a1c\"]\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_gmm2, palette=custom_palette)\n",
    "plt.title(\"GMM Clustering After PCA - 2 Clusters\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwrYbP-ArRX5",
    "outputId": "7ca5e090-a43e-4161-874b-e09b3fcc48c2"
   },
   "outputs": [],
   "source": [
    "gmm3 = GaussianMixture(n_components=3, random_state=2025)\n",
    "clusters_gmm3 = gmm3.fit_predict(X_scaled)\n",
    "\n",
    "data['GMM_cluster_3'] = clusters_gmm3\n",
    "\n",
    "print(\"Cluster distribution:\", np.bincount(clusters_gmm3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ERUapHhvrRVJ",
    "outputId": "604bfdbe-4ebb-42ae-d6af-7da8077226fb"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot GMM clusters\n",
    "plt.figure(figsize=(8,6))\n",
    "custom_palette = [\"#377eb8\",\"#e41a1c\",\"#E69F00\"]\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_gmm3, palette=custom_palette)\n",
    "plt.title(\"GMM Clustering After PCA - 3 Clusters\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "jXPGhfQ4rRSa",
    "outputId": "03012d51-46c3-4959-8536-c5bd91bc7acc"
   },
   "outputs": [],
   "source": [
    "n_components = range(1, 11)\n",
    "bics = []\n",
    "\n",
    "for n in n_components:\n",
    "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
    "    gmm.fit(X_scaled)\n",
    "    bics.append(gmm.bic(X_scaled))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(n_components, bics, marker='o', linestyle='-')\n",
    "ax.set_xlabel('Number of Components')\n",
    "ax.set_ylabel('BIC')\n",
    "ax.set_title('BIC for Optimal Number of Components in GMM')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z23KYH7psPkE"
   },
   "source": [
    "GMM has a decent level of performance, with three clusters, which suggests that the algorithm might be identifying the three orthopaedic classes detailed in the dataset description: normal, disk hernia, or spondylolisthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "id": "3DuOrhOGrRPz",
    "outputId": "024cf215-c4e3-49ac-a137-7e84fc9986e1"
   },
   "outputs": [],
   "source": [
    "# Create a figure with 3 subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 10))\n",
    "\n",
    "# Plot 1: GMM Clustering (2 Clusters)\n",
    "custom_palette_2 = [\"#377eb8\",\"#e41a1c\"]\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_gmm2, palette=custom_palette_2, ax=axes[0])\n",
    "axes[0].set_title(\"GMM Clustering After PCA - 2 Clusters\")\n",
    "axes[0].set_xlabel(\"Principal Component 1\")\n",
    "axes[0].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "# Plot 2: GMM Clustering (3 Clusters)\n",
    "custom_palette_3 = [\"#377eb8\",\"#e41a1c\",\"#E69F00\"]\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_gmm3, palette=custom_palette_3, ax=axes[1])\n",
    "axes[1].set_title(\"GMM Clustering After PCA - 3 Clusters\")\n",
    "axes[1].set_xlabel(\"Principal Component 1\")\n",
    "axes[1].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "# Plot 3: True Class Labels\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=data[\"class\"], palette=\"Set1\", ax=axes[2])\n",
    "axes[2].set_title(\"True Class Labels in PCA Space\")\n",
    "axes[2].set_xlabel(\"Principal Component 1\")\n",
    "axes[2].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the combined figure (optional)\n",
    "fig.savefig(\"GMM.jpeg\", format='jpeg', dpi=300)\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIWsaj5vsTUT"
   },
   "source": [
    "### 7.2. KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XE27A39PrRNP"
   },
   "outputs": [],
   "source": [
    "kmeans2 = KMeans(n_clusters=2, random_state=42, n_init=10)  # n_init=10 for better stability\n",
    "clusters_kmeans2 = kmeans2.fit_predict(X_scaled)\n",
    "\n",
    "# Add the clusters to the DataFrame\n",
    "data['KMeans_cluster2'] = clusters_kmeans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "ICsD5TOerRKf",
    "outputId": "f71d6b5c-1d25-4e41-ef04-fd7e7fd831b6"
   },
   "outputs": [],
   "source": [
    "# Plot K-Means clusters in PCA space\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_kmeans2, palette=\"Set1\")\n",
    "plt.title(\"K-Means Clustering After PCA - 2 Clusters\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBIGRr2QrRHw"
   },
   "outputs": [],
   "source": [
    "kmeans_3 = KMeans(n_clusters=3, random_state=42, n_init=10)  # n_init=10 for better stability\n",
    "clusters_kmeans_3 = kmeans_3.fit_predict(X_scaled)\n",
    "\n",
    "# Add the clusters to the DataFrame\n",
    "data['KMeans_cluster_3'] = clusters_kmeans_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "bQEsW5NKrRFL",
    "outputId": "74bae8e1-df08-4cde-ab89-8d6bc29d13b4"
   },
   "outputs": [],
   "source": [
    "# Plot K-Means clusters in PCA space\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_kmeans_3, palette=custom_palette)\n",
    "plt.title(\"K-Means Clustering After PCA - 3 Clusters\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "7FC2oSnpsfrv",
    "outputId": "83d1c4f6-e4ee-4fd7-e3fa-82051f58bc98"
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "K_range = range(1, 11)  # Try k from 1 to 10\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(K_range, inertia, marker='o', linestyle='-')\n",
    "ax.set_xlabel('Number of Clusters')\n",
    "ax.set_ylabel('Inertia')\n",
    "ax.set_title('Elbow Method for Optimal k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "id": "Mv966xB3sfMx",
    "outputId": "2c8e879b-66ea-4822-d5b6-274f2c1a04f1"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 10))\n",
    "\n",
    "# K-Means Clustering - 2 Clusters\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_kmeans2, palette=\"Set1\", ax=axes[0])\n",
    "axes[0].set_title(\"K-Means Clustering After PCA - 2 Clusters\")\n",
    "axes[0].set_xlabel(\"Principal Component 1\")\n",
    "axes[0].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "# K-Means Clustering - 3 Clusters\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters_kmeans_3, palette=custom_palette_3, ax=axes[1])\n",
    "axes[1].set_title(\"K-Means Clustering After PCA - 3 Clusters\")\n",
    "axes[1].set_xlabel(\"Principal Component 1\")\n",
    "axes[1].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "# True Class Labels\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=data[\"class\"], palette=\"Set1\", ax=axes[2])\n",
    "axes[2].set_title(\"True Class Labels in PCA Space\")\n",
    "axes[2].set_xlabel(\"Principal Component 1\")\n",
    "axes[2].set_ylabel(\"Principal Component 2\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmuQ62SYVpcs"
   },
   "source": [
    "## 7.3 Clustering Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74RyBnT7VwQ6"
   },
   "source": [
    "Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejSBEtUssuJb",
    "outputId": "a5adfecf-12c0-4c13-890c-dc2d8200063c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_kmeans = silhouette_score(X_scaled, clusters_kmeans2)\n",
    "silhouette_kmeans3 = silhouette_score(X_scaled, clusters_kmeans_3)\n",
    "\n",
    "silhouette_gmm = silhouette_score(X_scaled, clusters_gmm2)\n",
    "silhouette_gmm3 = silhouette_score(X_scaled, clusters_gmm3)\n",
    "\n",
    "print(\"Silhouette Score - KMeans (2):\", silhouette_kmeans)\n",
    "print(\"Silhouette Score - KMeans (3):\", silhouette_kmeans3)\n",
    "\n",
    "print(\"Silhouette Score - GMM (2):\", silhouette_gmm)\n",
    "print(\"Silhouette Score - GMM (3):\", silhouette_gmm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHIuvx6XWs52"
   },
   "source": [
    "David-Bouldin Index (DBI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKS2torGVvXP",
    "outputId": "7eb568ff-9b9d-4fdb-8809-421f65c5d964"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "dbi_kmeans = davies_bouldin_score(X_scaled, clusters_kmeans2)\n",
    "dbi_kmeans3 = davies_bouldin_score(X_scaled, clusters_kmeans_3)\n",
    "\n",
    "dbi_gmm = davies_bouldin_score(X_scaled, clusters_gmm2)\n",
    "dbi_gmm3 = davies_bouldin_score(X_scaled, clusters_gmm3)\n",
    "\n",
    "print(\"Davies-Bouldin Index - KMeans (2):\", dbi_kmeans)\n",
    "print(\"Davies-Bouldin Index - KMeans (3):\", dbi_kmeans3)\n",
    "\n",
    "print(\"Davies-Bouldin Index - GMM (2):\", dbi_gmm)\n",
    "print(\"Davies-Bouldin Index - GMM (3):\", dbi_gmm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGZ70XmHWxyb"
   },
   "source": [
    "Calinski-Harabasz Index (CHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SI-x7cSWvY1",
    "outputId": "065769ff-7a3a-4e6b-a26b-606ae1377b61"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "chi_kmeans = calinski_harabasz_score(X_scaled, clusters_kmeans2)\n",
    "chi_kmeans3 = calinski_harabasz_score(X_scaled, clusters_kmeans_3)\n",
    "\n",
    "chi_gmm = calinski_harabasz_score(X_scaled, clusters_gmm2)\n",
    "chi_gmm3 = calinski_harabasz_score(X_scaled, clusters_gmm3)\n",
    "\n",
    "print(\"Calinski-Harabasz Index - KMeans (2):\", chi_kmeans)\n",
    "print(\"Calinski-Harabasz Index - KMeans (3):\", chi_kmeans3)\n",
    "\n",
    "print(\"Calinski-Harabasz Index - GMM (2):\", chi_gmm)\n",
    "print(\"Calinski-Harabasz Index - GMM (3):\", chi_gmm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQXqlSG7W1bP"
   },
   "source": [
    "Log-likelihood of GMM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbRl2ccEWzaU",
    "outputId": "66218330-fbe9-42d8-c41e-2182cbd85153"
   },
   "outputs": [],
   "source": [
    "# 2 clusters\n",
    "log_likelihood_gmm_2 = gmm2.score(X_scaled)\n",
    "total_log_likelihood_gmm_2 = gmm2.score_samples(X_scaled).sum()\n",
    "\n",
    "# 3 clusters\n",
    "log_likelihood_gmm_3 = gmm3.score(X_scaled)\n",
    "total_log_likelihood_gmm_3 = gmm3.score_samples(X_scaled).sum()\n",
    "\n",
    "print(\"Log-Likelihood - GMM (2 clusters):\", total_log_likelihood_gmm_2)\n",
    "print(\"Log-Likelihood - GMM (3 clusters):\", total_log_likelihood_gmm_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3LlRF83W8WV",
    "outputId": "5530812f-e68c-4886-b0ab-69b776475523"
   },
   "outputs": [],
   "source": [
    "probabilities_2 = gmm2.predict_proba(X_scaled)\n",
    "probabilities_3 = gmm3.predict_proba(X_scaled)\n",
    "\n",
    "entropy_2 = -np.sum(probabilities_2 * np.log(probabilities_2 + 1e-10), axis=1)\n",
    "entropy_3 = -np.sum(probabilities_3 * np.log(probabilities_3 + 1e-10), axis=1)\n",
    "\n",
    "avg_entropy_2 = np.mean(entropy_2)\n",
    "avg_entropy_3 = np.mean(entropy_3)\n",
    "\n",
    "print(\"Average Entropy - GMM (2 clusters):\", avg_entropy_2)\n",
    "print(\"Average Entropy - GMM (3 clusters):\", avg_entropy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "45wUwqsvXA_Z",
    "outputId": "cf354e05-5501-4d5e-f454-33efc8d6ac86"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 6))\n",
    "\n",
    "titles = [\"Silhouette Score\", \"Davies-Bouldin Index\", \"Calinski-Harabasz Index\"]\n",
    "\n",
    "data = [\n",
    "    [0.3629, 0.2951, 0.3656, 0.2264],  # Silhouette Score\n",
    "    [1.1309, 1.2986, 1.1873, 1.4697],  # Davies-Bouldin Index\n",
    "    [189.3363, 153.5933, 143.4943, 106.7340],  # Calinski-Harabasz Index\n",
    "]\n",
    "\n",
    "bar_width = 0.8\n",
    "x_labels = [\"KM (2)\", \"KM(3)\", \"GMM (2)\", \"GMM (3)\"]\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "colors = [\"blue\", \"lightblue\", \"green\", \"lightgreen\"]\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    bars = ax.bar(x, data[i], width=bar_width, color=colors)\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.2f}\",\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=0)\n",
    "    ax.set_ylabel(\"Score\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
